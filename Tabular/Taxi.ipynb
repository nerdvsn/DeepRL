{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32dd32e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 16:07:17,960\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2025-07-29 16:07:18,317\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2025-07-29 16:07:20,969\tINFO worker.py:1927 -- Started a local Ray instance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"lm-Widget p-Widget lm-Panel p-Panel jp-Cell-outputWrapper\">\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <div class=\"jp-RenderedHTMLCommon\" style=\"display: flex; flex-direction: row;\">\n",
       "  <svg viewBox=\"0 0 567 224\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\" style=\"height: 3em;\">\n",
       "    <g clip-path=\"url(#clip0_4338_178347)\">\n",
       "        <path d=\"M341.29 165.561H355.29L330.13 129.051C345.63 123.991 354.21 112.051 354.21 94.2307C354.21 71.3707 338.72 58.1807 311.88 58.1807H271V165.561H283.27V131.661H311.8C314.25 131.661 316.71 131.501 319.01 131.351L341.25 165.561H341.29ZM283.29 119.851V70.0007H311.82C331.3 70.0007 342.34 78.2907 342.34 94.5507C342.34 111.271 331.34 119.861 311.82 119.861L283.29 119.851ZM451.4 138.411L463.4 165.561H476.74L428.74 58.1807H416L367.83 165.561H380.83L392.83 138.411H451.4ZM446.19 126.601H398L422 72.1407L446.24 126.601H446.19ZM526.11 128.741L566.91 58.1807H554.35L519.99 114.181L485.17 58.1807H472.44L514.01 129.181V165.541H526.13V128.741H526.11Z\" fill=\"var(--jp-ui-font-color0)\"/>\n",
       "        <path d=\"M82.35 104.44C84.0187 97.8827 87.8248 92.0678 93.1671 87.9146C98.5094 83.7614 105.083 81.5067 111.85 81.5067C118.617 81.5067 125.191 83.7614 130.533 87.9146C135.875 92.0678 139.681 97.8827 141.35 104.44H163.75C164.476 101.562 165.622 98.8057 167.15 96.2605L127.45 56.5605C121.071 60.3522 113.526 61.6823 106.235 60.3005C98.9443 58.9187 92.4094 54.9203 87.8602 49.0574C83.3109 43.1946 81.0609 35.8714 81.5332 28.4656C82.0056 21.0599 85.1679 14.0819 90.4252 8.8446C95.6824 3.60726 102.672 0.471508 110.08 0.0272655C117.487 -0.416977 124.802 1.86091 130.647 6.4324C136.493 11.0039 140.467 17.5539 141.821 24.8501C143.175 32.1463 141.816 39.6859 138 46.0505L177.69 85.7505C182.31 82.9877 187.58 81.4995 192.962 81.4375C198.345 81.3755 203.648 82.742 208.33 85.3976C213.012 88.0532 216.907 91.9029 219.616 96.5544C222.326 101.206 223.753 106.492 223.753 111.875C223.753 117.258 222.326 122.545 219.616 127.197C216.907 131.848 213.012 135.698 208.33 138.353C203.648 141.009 198.345 142.375 192.962 142.313C187.58 142.251 182.31 140.763 177.69 138L138 177.7C141.808 184.071 143.155 191.614 141.79 198.91C140.424 206.205 136.44 212.75 130.585 217.313C124.731 221.875 117.412 224.141 110.004 223.683C102.596 223.226 95.6103 220.077 90.3621 214.828C85.1139 209.58 81.9647 202.595 81.5072 195.187C81.0497 187.779 83.3154 180.459 87.878 174.605C92.4405 168.751 98.9853 164.766 106.281 163.401C113.576 162.035 121.119 163.383 127.49 167.19L167.19 127.49C165.664 124.941 164.518 122.182 163.79 119.3H141.39C139.721 125.858 135.915 131.673 130.573 135.826C125.231 139.98 118.657 142.234 111.89 142.234C105.123 142.234 98.5494 139.98 93.2071 135.826C87.8648 131.673 84.0587 125.858 82.39 119.3H60C58.1878 126.495 53.8086 132.78 47.6863 136.971C41.5641 141.163 34.1211 142.972 26.7579 142.059C19.3947 141.146 12.6191 137.574 7.70605 132.014C2.79302 126.454 0.0813599 119.29 0.0813599 111.87C0.0813599 104.451 2.79302 97.2871 7.70605 91.7272C12.6191 86.1673 19.3947 82.5947 26.7579 81.6817C34.1211 80.7686 41.5641 82.5781 47.6863 86.7696C53.8086 90.9611 58.1878 97.2456 60 104.44H82.35ZM100.86 204.32C103.407 206.868 106.759 208.453 110.345 208.806C113.93 209.159 117.527 208.258 120.522 206.256C123.517 204.254 125.725 201.276 126.771 197.828C127.816 194.38 127.633 190.677 126.253 187.349C124.874 184.021 122.383 181.274 119.205 179.577C116.027 177.88 112.359 177.337 108.826 178.042C105.293 178.746 102.113 180.654 99.8291 183.44C97.5451 186.226 96.2979 189.718 96.3 193.32C96.2985 195.364 96.7006 197.388 97.4831 199.275C98.2656 201.163 99.4132 202.877 100.86 204.32ZM204.32 122.88C206.868 120.333 208.453 116.981 208.806 113.396C209.159 109.811 208.258 106.214 206.256 103.219C204.254 100.223 201.275 98.0151 197.827 96.97C194.38 95.9249 190.676 96.1077 187.348 97.4873C184.02 98.8669 181.274 101.358 179.577 104.536C177.879 107.714 177.337 111.382 178.041 114.915C178.746 118.448 180.653 121.627 183.439 123.911C186.226 126.195 189.717 127.443 193.32 127.44C195.364 127.443 197.388 127.042 199.275 126.259C201.163 125.476 202.878 124.328 204.32 122.88ZM122.88 19.4205C120.333 16.8729 116.981 15.2876 113.395 14.9347C109.81 14.5817 106.213 15.483 103.218 17.4849C100.223 19.4868 98.0146 22.4654 96.9696 25.9131C95.9245 29.3608 96.1073 33.0642 97.4869 36.3922C98.8665 39.7202 101.358 42.4668 104.535 44.1639C107.713 45.861 111.381 46.4036 114.914 45.6992C118.447 44.9949 121.627 43.0871 123.911 40.301C126.195 37.515 127.442 34.0231 127.44 30.4205C127.44 28.3772 127.038 26.3539 126.255 24.4664C125.473 22.5788 124.326 20.8642 122.88 19.4205ZM19.42 100.86C16.8725 103.408 15.2872 106.76 14.9342 110.345C14.5813 113.93 15.4826 117.527 17.4844 120.522C19.4863 123.518 22.4649 125.726 25.9127 126.771C29.3604 127.816 33.0638 127.633 36.3918 126.254C39.7198 124.874 42.4664 122.383 44.1635 119.205C45.8606 116.027 46.4032 112.359 45.6988 108.826C44.9944 105.293 43.0866 102.114 40.3006 99.8296C37.5145 97.5455 34.0227 96.2983 30.42 96.3005C26.2938 96.3018 22.337 97.9421 19.42 100.86ZM100.86 100.86C98.3125 103.408 96.7272 106.76 96.3742 110.345C96.0213 113.93 96.9226 117.527 98.9244 120.522C100.926 123.518 103.905 125.726 107.353 126.771C110.8 127.816 114.504 127.633 117.832 126.254C121.16 124.874 123.906 122.383 125.604 119.205C127.301 116.027 127.843 112.359 127.139 108.826C126.434 105.293 124.527 102.114 121.741 99.8296C118.955 97.5455 115.463 96.2983 111.86 96.3005C109.817 96.299 107.793 96.701 105.905 97.4835C104.018 98.2661 102.303 99.4136 100.86 100.86Z\" fill=\"#00AEEF\"/>\n",
       "    </g>\n",
       "    <defs>\n",
       "        <clipPath id=\"clip0_4338_178347\">\n",
       "            <rect width=\"566.93\" height=\"223.75\" fill=\"white\"/>\n",
       "        </clipPath>\n",
       "    </defs>\n",
       "  </svg>\n",
       "</div>\n",
       "\n",
       "        <table class=\"jp-RenderedHTMLCommon\" style=\"border-collapse: collapse;color: var(--jp-ui-font-color1);font-size: var(--jp-ui-font-size1);\">\n",
       "    <tr>\n",
       "        <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "        <td style=\"text-align: left\"><b>3.10.18</b></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "        <td style=\"text-align: left\"><b>2.48.0</b></td>\n",
       "    </tr>\n",
       "    \n",
       "</table>\n",
       "\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='', python_version='3.10.18', ray_version='2.48.0', ray_commit='03491225d59a1ffde99c3628969ccf456be13efd')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import ray\n",
    "from ray import tune\n",
    "\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray.rllib.connectors.env_to_module import FlattenObservations\n",
    "\n",
    "\n",
    "# 1. Ray initialisieren\n",
    "ray.init(ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b3e439b",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"Taxi-v3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e772e909",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 16:41:12,255\tWARNING algorithm_config.py:4921 -- You have specified 1 evaluation workers, but your `evaluation_interval` is 0 or None! Therefore, evaluation doesn't occur automatically with each call to `Algorithm.train()`. Instead, you have to call `Algorithm.evaluate()` manually in order to trigger an evaluation run.\n",
      "[2025-07-29 16:41:12,286 E 125052 125052] core_worker.cc:2740: Actor with class name: 'SingleAgentEnvRunner' and ID: 'ef9cccc00f18fdbbf162b8d001000000' has constructor arguments in the object store and max_restarts > 0. If the arguments in the object store go out of scope or are lost, the actor restart will fail. See https://github.com/ray-project/ray/issues/53727 for more details.\n",
      "[2025-07-29 16:41:12,314 E 125052 125052] core_worker.cc:2740: Actor with class name: 'SingleAgentEnvRunner' and ID: '6c43182a9bf55a48e2620a6c01000000' has constructor arguments in the object store and max_restarts > 0. If the arguments in the object store go out of scope or are lost, the actor restart will fail. See https://github.com/ray-project/ray/issues/53727 for more details.\n",
      "\u001b[36m(SingleAgentEnvRunner pid=247913)\u001b[0m 2025-07-29 16:41:14,644\tERROR algorithm_config.py:1032 -- Your `config.env_to_module_connector` function seems to have a wrong or outdated signature! It should be: `def myfunc(env, spaces, device): ...`, where any of these arguments are optional and may be None.\n",
      "\u001b[36m(SingleAgentEnvRunner pid=247913)\u001b[0m `env` is the (vectorized) gym env.\n",
      "\u001b[36m(SingleAgentEnvRunner pid=247913)\u001b[0m `spaces` is a dict of structure `{'__env__': ([vectorized env obs. space, vectorized env act. space]),'__env_single__': ([env obs. space, env act. space])}`.\n",
      "\u001b[36m(SingleAgentEnvRunner pid=247913)\u001b[0m `device` is a (torch) device.\n",
      "\u001b[36m(SingleAgentEnvRunner pid=247913)\u001b[0m \n",
      "\u001b[36m(SingleAgentEnvRunner pid=247914)\u001b[0m \n",
      "\u001b[36m(SingleAgentEnvRunner pid=247913)\u001b[0m 2025-07-29 16:41:14,734\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\n",
      "2025-07-29 16:41:14,831\tWARNING algorithm_config.py:4921 -- You have specified 1 evaluation workers, but your `evaluation_interval` is 0 or None! Therefore, evaluation doesn't occur automatically with each call to `Algorithm.train()`. Instead, you have to call `Algorithm.evaluate()` manually in order to trigger an evaluation run.\n",
      "[2025-07-29 16:41:14,861 E 125052 125052] core_worker.cc:2740: Actor with class name: 'SingleAgentEnvRunner' and ID: 'bbddd142a06e27cfaf52114101000000' has constructor arguments in the object store and max_restarts > 0. If the arguments in the object store go out of scope or are lost, the actor restart will fail. See https://github.com/ray-project/ray/issues/53727 for more details.\n",
      "\u001b[36m(SingleAgentEnvRunner pid=248022)\u001b[0m \n",
      "2025-07-29 16:41:17,153\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "# Configure the algorithm.\n",
    "config = (\n",
    "    PPOConfig()\n",
    "    .environment(env=env_name)\n",
    "    .framework(\"torch\")\n",
    "    .env_runners(\n",
    "        num_env_runners=2,\n",
    "        # Observations are discrete (ints) -> We need to flatten (one-hot) them.\n",
    "        env_to_module_connector=lambda env: FlattenObservations(),\n",
    "    )\n",
    "    .evaluation(evaluation_num_env_runners=1)\n",
    "    .resources(num_gpus=1)\n",
    ")\n",
    "\n",
    "# Build the algorithm.\n",
    "algo = config.build_algo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "483cc19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 \n",
      "{'config': {'_disable_action_flattening': False,\n",
      "            '_disable_execution_plan_api': -1,\n",
      "            '_disable_initialize_loss_from_dummy_batch': False,\n",
      "            '_disable_preprocessor_api': False,\n",
      "            '_dont_auto_sync_env_runner_states': False,\n",
      "            '_enable_rl_module_api': -1,\n",
      "            '_env_to_module_connector': <function <lambda> at 0x723958b9c3a0>,\n",
      "            '_fake_gpus': False,\n",
      "            '_is_atari': None,\n",
      "            '_is_online': True,\n",
      "            '_learner_class': None,\n",
      "            '_learner_connector': None,\n",
      "            '_model_config': {},\n",
      "            '_module_to_env_connector': None,\n",
      "            '_per_module_overrides': {},\n",
      "            '_prior_exploration_config': {'type': 'StochasticSampling'},\n",
      "            '_rl_module_spec': None,\n",
      "            '_tf_policy_handles_more_than_one_loss': False,\n",
      "            '_torch_grad_scaler_class': None,\n",
      "            '_torch_lr_scheduler_classes': None,\n",
      "            '_train_batch_size_per_learner': None,\n",
      "            '_use_msgpack_checkpoints': False,\n",
      "            '_validate_config': True,\n",
      "            'action_mask_key': 'action_mask',\n",
      "            'action_space': None,\n",
      "            'actions_in_input_normalized': False,\n",
      "            'add_default_connectors_to_env_to_module_pipeline': True,\n",
      "            'add_default_connectors_to_learner_pipeline': True,\n",
      "            'add_default_connectors_to_module_to_env_pipeline': True,\n",
      "            'algorithm_config_overrides_per_module': {},\n",
      "            'always_attach_evaluation_results': -1,\n",
      "            'auto_wrap_old_gym_envs': -1,\n",
      "            'batch_mode': 'truncate_episodes',\n",
      "            'broadcast_env_runner_states': True,\n",
      "            'broadcast_offline_eval_runner_states': False,\n",
      "            'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>,\n",
      "            'callbacks_on_algorithm_init': None,\n",
      "            'callbacks_on_checkpoint_loaded': None,\n",
      "            'callbacks_on_env_runners_recreated': None,\n",
      "            'callbacks_on_environment_created': None,\n",
      "            'callbacks_on_episode_created': None,\n",
      "            'callbacks_on_episode_end': None,\n",
      "            'callbacks_on_episode_start': None,\n",
      "            'callbacks_on_episode_step': None,\n",
      "            'callbacks_on_evaluate_end': None,\n",
      "            'callbacks_on_evaluate_offline_end': None,\n",
      "            'callbacks_on_evaluate_offline_start': None,\n",
      "            'callbacks_on_evaluate_start': None,\n",
      "            'callbacks_on_offline_eval_runners_recreated': None,\n",
      "            'callbacks_on_sample_end': None,\n",
      "            'callbacks_on_train_result': None,\n",
      "            'checkpoint_trainable_policies_only': False,\n",
      "            'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>,\n",
      "            'clip_actions': False,\n",
      "            'clip_param': 0.3,\n",
      "            'clip_rewards': None,\n",
      "            'compress_observations': False,\n",
      "            'count_steps_by': 'env_steps',\n",
      "            'create_env_on_driver': False,\n",
      "            'create_local_env_runner': True,\n",
      "            'custom_async_evaluation_function': -1,\n",
      "            'custom_eval_function': None,\n",
      "            'custom_resources_per_env_runner': {},\n",
      "            'custom_resources_per_offline_eval_runner': {},\n",
      "            'dataset_num_iters_per_eval_runner': 1,\n",
      "            'dataset_num_iters_per_learner': None,\n",
      "            'delay_between_env_runner_restarts_s': 60.0,\n",
      "            'disable_env_checking': False,\n",
      "            'eager_max_retraces': 20,\n",
      "            'eager_tracing': True,\n",
      "            'enable_async_evaluation': -1,\n",
      "            'enable_connectors': -1,\n",
      "            'enable_env_runner_and_connector_v2': True,\n",
      "            'enable_rl_module_and_learner': True,\n",
      "            'enable_tf1_exec_eagerly': False,\n",
      "            'entropy_coeff': 0.0,\n",
      "            'entropy_coeff_schedule': None,\n",
      "            'env': 'Taxi-v3',\n",
      "            'env_config': {},\n",
      "            'env_runner_cls': None,\n",
      "            'env_runner_health_probe_timeout_s': 30.0,\n",
      "            'env_runner_restore_timeout_s': 1800.0,\n",
      "            'env_task_fn': -1,\n",
      "            'episode_lookback_horizon': 1,\n",
      "            'episodes_to_numpy': True,\n",
      "            'evaluation_auto_duration_max_env_steps_per_sample': 2000,\n",
      "            'evaluation_auto_duration_min_env_steps_per_sample': 100,\n",
      "            'evaluation_config': None,\n",
      "            'evaluation_duration': 10,\n",
      "            'evaluation_duration_unit': 'episodes',\n",
      "            'evaluation_force_reset_envs_before_iteration': True,\n",
      "            'evaluation_interval': None,\n",
      "            'evaluation_num_env_runners': 1,\n",
      "            'evaluation_parallel_to_training': False,\n",
      "            'evaluation_sample_timeout_s': 120.0,\n",
      "            'exploration_config': {},\n",
      "            'explore': True,\n",
      "            'export_native_model_files': False,\n",
      "            'extra_python_environs_for_driver': {},\n",
      "            'extra_python_environs_for_worker': {},\n",
      "            'fake_sampler': False,\n",
      "            'framework': 'torch',\n",
      "            'gamma': 0.99,\n",
      "            'grad_clip': None,\n",
      "            'grad_clip_by': 'global_norm',\n",
      "            'gym_env_vectorize_mode': 'SYNC',\n",
      "            'ignore_env_runner_failures': False,\n",
      "            'ignore_final_observation': False,\n",
      "            'ignore_offline_eval_runner_failures': False,\n",
      "            'in_evaluation': False,\n",
      "            'input': 'sampler',\n",
      "            'input_compress_columns': ['obs', 'new_obs'],\n",
      "            'input_config': {},\n",
      "            'input_filesystem': None,\n",
      "            'input_filesystem_kwargs': {},\n",
      "            'input_read_batch_size': None,\n",
      "            'input_read_episodes': False,\n",
      "            'input_read_method': 'read_parquet',\n",
      "            'input_read_method_kwargs': {},\n",
      "            'input_read_sample_batches': False,\n",
      "            'input_read_schema': {},\n",
      "            'input_spaces_jsonable': True,\n",
      "            'iter_batches_kwargs': {},\n",
      "            'keep_per_episode_custom_metrics': False,\n",
      "            'kl_coeff': 0.2,\n",
      "            'kl_target': 0.01,\n",
      "            'lambda': 1.0,\n",
      "            'learner_config_dict': {},\n",
      "            'local_gpu_idx': 0,\n",
      "            'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
      "                                      'intra_op_parallelism_threads': 8},\n",
      "            'log_gradients': True,\n",
      "            'log_level': 'WARN',\n",
      "            'log_sys_usage': True,\n",
      "            'logger_config': None,\n",
      "            'logger_creator': None,\n",
      "            'lr': 5e-05,\n",
      "            'lr_schedule': None,\n",
      "            'map_batches_kwargs': {},\n",
      "            'materialize_data': False,\n",
      "            'materialize_mapped_data': True,\n",
      "            'max_num_env_runner_restarts': 1000,\n",
      "            'max_num_offline_eval_runner_restarts': 1000,\n",
      "            'max_requests_in_flight_per_aggregator_actor': 3,\n",
      "            'max_requests_in_flight_per_env_runner': 1,\n",
      "            'max_requests_in_flight_per_learner': 3,\n",
      "            'max_requests_in_flight_per_offline_eval_runner': 1,\n",
      "            'merge_env_runner_states': 'training_only',\n",
      "            'metrics_episode_collection_timeout_s': 60.0,\n",
      "            'metrics_num_episodes_for_smoothing': 100,\n",
      "            'min_sample_timesteps_per_iteration': 0,\n",
      "            'min_time_s_per_iteration': None,\n",
      "            'min_train_timesteps_per_iteration': 0,\n",
      "            'minibatch_size': 128,\n",
      "            'model': {'_disable_action_flattening': False,\n",
      "                      '_disable_preprocessor_api': False,\n",
      "                      '_time_major': False,\n",
      "                      '_use_default_native_models': -1,\n",
      "                      'always_check_shapes': False,\n",
      "                      'attention_dim': 64,\n",
      "                      'attention_head_dim': 32,\n",
      "                      'attention_init_gru_gate_bias': 2.0,\n",
      "                      'attention_memory_inference': 50,\n",
      "                      'attention_memory_training': 50,\n",
      "                      'attention_num_heads': 1,\n",
      "                      'attention_num_transformer_units': 1,\n",
      "                      'attention_position_wise_mlp_dim': 32,\n",
      "                      'attention_use_n_prev_actions': 0,\n",
      "                      'attention_use_n_prev_rewards': 0,\n",
      "                      'conv_activation': 'relu',\n",
      "                      'conv_bias_initializer': None,\n",
      "                      'conv_bias_initializer_config': None,\n",
      "                      'conv_filters': None,\n",
      "                      'conv_kernel_initializer': None,\n",
      "                      'conv_kernel_initializer_config': None,\n",
      "                      'conv_transpose_bias_initializer': None,\n",
      "                      'conv_transpose_bias_initializer_config': None,\n",
      "                      'conv_transpose_kernel_initializer': None,\n",
      "                      'conv_transpose_kernel_initializer_config': None,\n",
      "                      'custom_action_dist': None,\n",
      "                      'custom_model': None,\n",
      "                      'custom_model_config': {},\n",
      "                      'custom_preprocessor': None,\n",
      "                      'dim': 84,\n",
      "                      'encoder_latent_dim': None,\n",
      "                      'fcnet_activation': 'tanh',\n",
      "                      'fcnet_bias_initializer': None,\n",
      "                      'fcnet_bias_initializer_config': None,\n",
      "                      'fcnet_hiddens': [256, 256],\n",
      "                      'fcnet_weights_initializer': None,\n",
      "                      'fcnet_weights_initializer_config': None,\n",
      "                      'framestack': True,\n",
      "                      'free_log_std': False,\n",
      "                      'grayscale': False,\n",
      "                      'log_std_clip_param': 20.0,\n",
      "                      'lstm_bias_initializer': None,\n",
      "                      'lstm_bias_initializer_config': None,\n",
      "                      'lstm_cell_size': 256,\n",
      "                      'lstm_use_prev_action': False,\n",
      "                      'lstm_use_prev_action_reward': -1,\n",
      "                      'lstm_use_prev_reward': False,\n",
      "                      'lstm_weights_initializer': None,\n",
      "                      'lstm_weights_initializer_config': None,\n",
      "                      'max_seq_len': 20,\n",
      "                      'no_final_linear': False,\n",
      "                      'post_fcnet_activation': 'relu',\n",
      "                      'post_fcnet_bias_initializer': None,\n",
      "                      'post_fcnet_bias_initializer_config': None,\n",
      "                      'post_fcnet_hiddens': [],\n",
      "                      'post_fcnet_weights_initializer': None,\n",
      "                      'post_fcnet_weights_initializer_config': None,\n",
      "                      'use_attention': False,\n",
      "                      'use_lstm': False,\n",
      "                      'vf_share_layers': False,\n",
      "                      'zero_mean': True},\n",
      "            'normalize_actions': True,\n",
      "            'num_aggregator_actors_per_learner': 0,\n",
      "            'num_consecutive_env_runner_failures_tolerance': 100,\n",
      "            'num_cpus_for_main_process': 1,\n",
      "            'num_cpus_per_env_runner': 1,\n",
      "            'num_cpus_per_learner': 'auto',\n",
      "            'num_cpus_per_offline_eval_runner': 1,\n",
      "            'num_env_runners': 2,\n",
      "            'num_envs_per_env_runner': 1,\n",
      "            'num_epochs': 30,\n",
      "            'num_gpus': 1,\n",
      "            'num_gpus_per_env_runner': 0,\n",
      "            'num_gpus_per_learner': 0,\n",
      "            'num_gpus_per_offline_eval_runner': 0,\n",
      "            'num_learners': 0,\n",
      "            'num_offline_eval_runners': 0,\n",
      "            'observation_filter': 'NoFilter',\n",
      "            'observation_fn': None,\n",
      "            'observation_space': None,\n",
      "            'off_policy_estimation_methods': {},\n",
      "            'offline_data_class': None,\n",
      "            'offline_eval_batch_size_per_runner': 256,\n",
      "            'offline_eval_rl_module_inference_only': False,\n",
      "            'offline_eval_runner_class': None,\n",
      "            'offline_eval_runner_health_probe_timeout_s': 30.0,\n",
      "            'offline_eval_runner_restore_timeout_s': 1800.0,\n",
      "            'offline_evaluation_duration': 1,\n",
      "            'offline_evaluation_interval': None,\n",
      "            'offline_evaluation_parallel_to_training': False,\n",
      "            'offline_evaluation_timeout_s': 120.0,\n",
      "            'offline_evaluation_type': None,\n",
      "            'offline_loss_for_module_fn': None,\n",
      "            'offline_sampling': False,\n",
      "            'ope_split_batch_by_episode': True,\n",
      "            'optimizer': {},\n",
      "            'output': None,\n",
      "            'output_compress_columns': ['obs', 'new_obs'],\n",
      "            'output_config': {},\n",
      "            'output_filesystem': None,\n",
      "            'output_filesystem_kwargs': {},\n",
      "            'output_max_file_size': 67108864,\n",
      "            'output_max_rows_per_file': None,\n",
      "            'output_write_episodes': True,\n",
      "            'output_write_method': 'write_parquet',\n",
      "            'output_write_method_kwargs': {},\n",
      "            'output_write_remaining_data': False,\n",
      "            'placement_strategy': 'PACK',\n",
      "            'policies': {'default_policy': (None, None, None, None)},\n",
      "            'policies_to_train': None,\n",
      "            'policy_map_cache': -1,\n",
      "            'policy_map_capacity': 100,\n",
      "            'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x723b51995ea0>,\n",
      "            'policy_states_are_swappable': False,\n",
      "            'postprocess_inputs': False,\n",
      "            'prelearner_buffer_class': None,\n",
      "            'prelearner_buffer_kwargs': {},\n",
      "            'prelearner_class': None,\n",
      "            'prelearner_module_synch_period': 10,\n",
      "            'preprocessor_pref': 'deepmind',\n",
      "            'remote_env_batch_wait_ms': 0,\n",
      "            'remote_worker_envs': False,\n",
      "            'render_env': False,\n",
      "            'replay_sequence_length': None,\n",
      "            'restart_failed_env_runners': True,\n",
      "            'restart_failed_offline_eval_runners': True,\n",
      "            'restart_failed_sub_environments': False,\n",
      "            'rollout_fragment_length': 'auto',\n",
      "            'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
      "            'sample_timeout_s': 60.0,\n",
      "            'sampler_perf_stats_ema_coef': None,\n",
      "            'seed': None,\n",
      "            'sgd_minibatch_size': -1,\n",
      "            'shuffle_batch_per_epoch': True,\n",
      "            'shuffle_buffer_size': 0,\n",
      "            'simple_optimizer': False,\n",
      "            'sync_filters_on_rollout_workers_timeout_s': 10.0,\n",
      "            'synchronize_filters': -1,\n",
      "            'tf_session_args': {'allow_soft_placement': True,\n",
      "                                'device_count': {'CPU': 1},\n",
      "                                'gpu_options': {'allow_growth': True},\n",
      "                                'inter_op_parallelism_threads': 2,\n",
      "                                'intra_op_parallelism_threads': 2,\n",
      "                                'log_device_placement': False},\n",
      "            'torch_compile_learner': False,\n",
      "            'torch_compile_learner_dynamo_backend': 'inductor',\n",
      "            'torch_compile_learner_dynamo_mode': None,\n",
      "            'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>,\n",
      "            'torch_compile_worker': False,\n",
      "            'torch_compile_worker_dynamo_backend': 'onnxrt',\n",
      "            'torch_compile_worker_dynamo_mode': None,\n",
      "            'torch_ddp_kwargs': {},\n",
      "            'torch_skip_nan_gradients': False,\n",
      "            'train_batch_size': 4000,\n",
      "            'update_worker_filter_stats': True,\n",
      "            'use_critic': True,\n",
      "            'use_gae': True,\n",
      "            'use_kl_loss': True,\n",
      "            'use_worker_filter_stats': True,\n",
      "            'validate_env_runners_after_construction': True,\n",
      "            'validate_offline_eval_runners_after_construction': True,\n",
      "            'vf_clip_param': 10.0,\n",
      "            'vf_loss_coeff': 1.0,\n",
      "            'vf_share_layers': -1,\n",
      "            'worker_cls': -1},\n",
      " 'date': '2025-07-29_16-43-06',\n",
      " 'done': False,\n",
      " 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0},\n",
      " 'env_runners': {'agent_episode_return_mean': {'default_agent': -584.52},\n",
      "                 'env_reset_timer': np.float64(0.00033264499870711006),\n",
      "                 'env_step_timer': np.float64(7.545500194240959e-05),\n",
      "                 'env_to_module_connector': {'connector_pipeline_timer': np.float64(0.0002022576859934273),\n",
      "                                             'timers': {'connectors': {'add_observations_from_episodes_to_batch': np.float64(7.891092634811717e-06),\n",
      "                                                                       'add_states_from_episodes_to_batch': np.float64(4.861261255104339e-06),\n",
      "                                                                       'add_time_dim_to_batch_and_zero_pad': np.float64(7.789501531262717e-06),\n",
      "                                                                       'batch_individual_items': np.float64(2.087393465856112e-05),\n",
      "                                                                       'flatten_observations': np.float64(4.6399471504037556e-05),\n",
      "                                                                       'numpy_to_tensor': np.float64(3.3848640868067116e-05)}}},\n",
      "                 'env_to_module_sum_episodes_length_in': np.float64(86.48791530594988),\n",
      "                 'env_to_module_sum_episodes_length_out': np.float64(86.48791530594988),\n",
      "                 'episode_duration_sec_mean': 0.19368797445989913,\n",
      "                 'episode_len_max': 200,\n",
      "                 'episode_len_mean': 198.12,\n",
      "                 'episode_len_min': 106,\n",
      "                 'episode_return_max': -247.0,\n",
      "                 'episode_return_mean': -584.52,\n",
      "                 'episode_return_min': -740.0,\n",
      "                 'module_episode_return_mean': {'default_policy': -584.52},\n",
      "                 'module_to_env_connector': {'connector_pipeline_timer': np.float64(0.00039320066954831015),\n",
      "                                             'timers': {'connectors': {'get_actions': np.float64(0.00016708949280149304),\n",
      "                                                                       'listify_data_for_vector_env': np.float64(3.4497020113449635e-05),\n",
      "                                                                       'normalize_and_clip_actions': np.float64(2.996424405401936e-05),\n",
      "                                                                       'remove_single_ts_time_rank_from_batch': np.float64(1.8983079078165932e-06),\n",
      "                                                                       'tensor_to_numpy': np.float64(5.172017632138505e-05),\n",
      "                                                                       'un_batch_to_individual_items': np.float64(1.7573161334316406e-05)}}},\n",
      "                 'num_agent_steps_sampled': {'default_agent': 4000.0},\n",
      "                 'num_agent_steps_sampled_lifetime': {'default_agent': 20000.0},\n",
      "                 'num_env_steps_sampled': 4000.0,\n",
      "                 'num_env_steps_sampled_lifetime': 20000.0,\n",
      "                 'num_env_steps_sampled_lifetime_throughput': np.float64(70.4709254579416),\n",
      "                 'num_episodes': 20.0,\n",
      "                 'num_episodes_lifetime': 100.0,\n",
      "                 'num_module_steps_sampled': {'default_policy': 4000.0},\n",
      "                 'num_module_steps_sampled_lifetime': {'default_policy': 20000.0},\n",
      "                 'rlmodule_inference_timer': np.float64(0.00012166620259645755),\n",
      "                 'sample': np.float64(2.05189934005604),\n",
      "                 'time_between_sampling': np.float64(17.50387478523801),\n",
      "                 'weights_seq_no': 4.0},\n",
      " 'fault_tolerance': {'num_healthy_workers': 2, 'num_remote_worker_restarts': 0},\n",
      " 'hostname': 'lukelo-Blade-15-Advanced-Model-Early-2020-RZ09-033',\n",
      " 'iterations_since_restore': 5,\n",
      " 'learners': {'__all_modules__': {'learner_connector': {'connector_pipeline_timer': 0.13132949253905488,\n",
      "                                                        'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.06115863993995509,\n",
      "                                                                                  'add_observations_from_episodes_to_batch': 0.0002162500909223603,\n",
      "                                                                                  'add_one_ts_to_episodes_and_truncate': 0.00617811958928473,\n",
      "                                                                                  'add_states_from_episodes_to_batch': 8.314478752717622e-06,\n",
      "                                                                                  'add_time_dim_to_batch_and_zero_pad': 2.2824421245821574e-05,\n",
      "                                                                                  'batch_individual_items': 0.04053831502509615,\n",
      "                                                                                  'general_advantage_estimation': 0.022684543549553262,\n",
      "                                                                                  'numpy_to_tensor': 0.00015439481600247701}}},\n",
      "                                  'learner_connector_sum_episodes_length_in': 4000.0,\n",
      "                                  'learner_connector_sum_episodes_length_out': 4021.0099999999998,\n",
      "                                  'num_env_steps_trained': 3792746,\n",
      "                                  'num_env_steps_trained_lifetime': 18959958,\n",
      "                                  'num_env_steps_trained_lifetime_throughput': 571910.4097667511,\n",
      "                                  'num_module_steps_trained': 120704,\n",
      "                                  'num_module_steps_trained_lifetime': 603520,\n",
      "                                  'num_module_steps_trained_lifetime_throughput': 18206.76597872502,\n",
      "                                  'num_module_steps_trained_throughput': 18205.878200266125,\n",
      "                                  'num_non_trainable_parameters': 0,\n",
      "                                  'num_trainable_parameters': 389895},\n",
      "              'default_policy': {'curr_entropy_coeff': 0.0,\n",
      "                                 'curr_kl_coeff': 0.675000011920929,\n",
      "                                 'default_optimizer_learning_rate': 5e-05,\n",
      "                                 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0),\n",
      "                                 'entropy': np.float32(1.6323851),\n",
      "                                 'gradients_default_optimizer_global_norm': np.float32(0.53908336),\n",
      "                                 'mean_kl_loss': np.float32(0.023526277),\n",
      "                                 'module_train_batch_size_mean': 128.0,\n",
      "                                 'num_module_steps_trained': 120704,\n",
      "                                 'num_module_steps_trained_lifetime': 603520,\n",
      "                                 'num_module_steps_trained_lifetime_throughput': 18205.049964110938,\n",
      "                                 'num_trainable_parameters': 389895,\n",
      "                                 'policy_loss': np.float32(-0.10005289),\n",
      "                                 'total_loss': np.float32(9.836664),\n",
      "                                 'vf_explained_var': np.float32(0.0030429363),\n",
      "                                 'vf_loss': np.float32(9.92613),\n",
      "                                 'vf_loss_unclipped': np.float32(28005.85),\n",
      "                                 'weights_seq_no': 5.0}},\n",
      " 'node_ip': '10.9.22.224',\n",
      " 'num_env_steps_sampled_lifetime': 20000.0,\n",
      " 'num_training_step_calls_per_iteration': 1,\n",
      " 'perf': {'cpu_util_percent': np.float64(14.846808510638297),\n",
      "          'ram_util_percent': np.float64(51.827659574468065)},\n",
      " 'pid': 125052,\n",
      " 'time_since_restore': 47.68227005004883,\n",
      " 'time_this_iter_s': 9.375411748886108,\n",
      " 'time_total_s': 47.68227005004883,\n",
      " 'timers': {'env_runner_sampling_timer': 2.1177301644953332,\n",
      "            'learner_update_timer': 7.311795999062622,\n",
      "            'restore_env_runners': 1.3445247307735191e-05,\n",
      "            'synch_env_connectors': 0.001924899914418478,\n",
      "            'synch_weights': 0.0019227547461067205,\n",
      "            'training_iteration': 9.434051462476596,\n",
      "            'training_step': 9.43380267537725},\n",
      " 'timestamp': 1753800186,\n",
      " 'training_iteration': 5,\n",
      " 'trial_id': 'default'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 \n",
      "{'config': {'_disable_action_flattening': False,\n",
      "            '_disable_execution_plan_api': -1,\n",
      "            '_disable_initialize_loss_from_dummy_batch': False,\n",
      "            '_disable_preprocessor_api': False,\n",
      "            '_dont_auto_sync_env_runner_states': False,\n",
      "            '_enable_rl_module_api': -1,\n",
      "            '_env_to_module_connector': <function <lambda> at 0x723958b9c3a0>,\n",
      "            '_fake_gpus': False,\n",
      "            '_is_atari': None,\n",
      "            '_is_online': True,\n",
      "            '_learner_class': None,\n",
      "            '_learner_connector': None,\n",
      "            '_model_config': {},\n",
      "            '_module_to_env_connector': None,\n",
      "            '_per_module_overrides': {},\n",
      "            '_prior_exploration_config': {'type': 'StochasticSampling'},\n",
      "            '_rl_module_spec': None,\n",
      "            '_tf_policy_handles_more_than_one_loss': False,\n",
      "            '_torch_grad_scaler_class': None,\n",
      "            '_torch_lr_scheduler_classes': None,\n",
      "            '_train_batch_size_per_learner': None,\n",
      "            '_use_msgpack_checkpoints': False,\n",
      "            '_validate_config': True,\n",
      "            'action_mask_key': 'action_mask',\n",
      "            'action_space': None,\n",
      "            'actions_in_input_normalized': False,\n",
      "            'add_default_connectors_to_env_to_module_pipeline': True,\n",
      "            'add_default_connectors_to_learner_pipeline': True,\n",
      "            'add_default_connectors_to_module_to_env_pipeline': True,\n",
      "            'algorithm_config_overrides_per_module': {},\n",
      "            'always_attach_evaluation_results': -1,\n",
      "            'auto_wrap_old_gym_envs': -1,\n",
      "            'batch_mode': 'truncate_episodes',\n",
      "            'broadcast_env_runner_states': True,\n",
      "            'broadcast_offline_eval_runner_states': False,\n",
      "            'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>,\n",
      "            'callbacks_on_algorithm_init': None,\n",
      "            'callbacks_on_checkpoint_loaded': None,\n",
      "            'callbacks_on_env_runners_recreated': None,\n",
      "            'callbacks_on_environment_created': None,\n",
      "            'callbacks_on_episode_created': None,\n",
      "            'callbacks_on_episode_end': None,\n",
      "            'callbacks_on_episode_start': None,\n",
      "            'callbacks_on_episode_step': None,\n",
      "            'callbacks_on_evaluate_end': None,\n",
      "            'callbacks_on_evaluate_offline_end': None,\n",
      "            'callbacks_on_evaluate_offline_start': None,\n",
      "            'callbacks_on_evaluate_start': None,\n",
      "            'callbacks_on_offline_eval_runners_recreated': None,\n",
      "            'callbacks_on_sample_end': None,\n",
      "            'callbacks_on_train_result': None,\n",
      "            'checkpoint_trainable_policies_only': False,\n",
      "            'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>,\n",
      "            'clip_actions': False,\n",
      "            'clip_param': 0.3,\n",
      "            'clip_rewards': None,\n",
      "            'compress_observations': False,\n",
      "            'count_steps_by': 'env_steps',\n",
      "            'create_env_on_driver': False,\n",
      "            'create_local_env_runner': True,\n",
      "            'custom_async_evaluation_function': -1,\n",
      "            'custom_eval_function': None,\n",
      "            'custom_resources_per_env_runner': {},\n",
      "            'custom_resources_per_offline_eval_runner': {},\n",
      "            'dataset_num_iters_per_eval_runner': 1,\n",
      "            'dataset_num_iters_per_learner': None,\n",
      "            'delay_between_env_runner_restarts_s': 60.0,\n",
      "            'disable_env_checking': False,\n",
      "            'eager_max_retraces': 20,\n",
      "            'eager_tracing': True,\n",
      "            'enable_async_evaluation': -1,\n",
      "            'enable_connectors': -1,\n",
      "            'enable_env_runner_and_connector_v2': True,\n",
      "            'enable_rl_module_and_learner': True,\n",
      "            'enable_tf1_exec_eagerly': False,\n",
      "            'entropy_coeff': 0.0,\n",
      "            'entropy_coeff_schedule': None,\n",
      "            'env': 'Taxi-v3',\n",
      "            'env_config': {},\n",
      "            'env_runner_cls': None,\n",
      "            'env_runner_health_probe_timeout_s': 30.0,\n",
      "            'env_runner_restore_timeout_s': 1800.0,\n",
      "            'env_task_fn': -1,\n",
      "            'episode_lookback_horizon': 1,\n",
      "            'episodes_to_numpy': True,\n",
      "            'evaluation_auto_duration_max_env_steps_per_sample': 2000,\n",
      "            'evaluation_auto_duration_min_env_steps_per_sample': 100,\n",
      "            'evaluation_config': None,\n",
      "            'evaluation_duration': 10,\n",
      "            'evaluation_duration_unit': 'episodes',\n",
      "            'evaluation_force_reset_envs_before_iteration': True,\n",
      "            'evaluation_interval': None,\n",
      "            'evaluation_num_env_runners': 1,\n",
      "            'evaluation_parallel_to_training': False,\n",
      "            'evaluation_sample_timeout_s': 120.0,\n",
      "            'exploration_config': {},\n",
      "            'explore': True,\n",
      "            'export_native_model_files': False,\n",
      "            'extra_python_environs_for_driver': {},\n",
      "            'extra_python_environs_for_worker': {},\n",
      "            'fake_sampler': False,\n",
      "            'framework': 'torch',\n",
      "            'gamma': 0.99,\n",
      "            'grad_clip': None,\n",
      "            'grad_clip_by': 'global_norm',\n",
      "            'gym_env_vectorize_mode': 'SYNC',\n",
      "            'ignore_env_runner_failures': False,\n",
      "            'ignore_final_observation': False,\n",
      "            'ignore_offline_eval_runner_failures': False,\n",
      "            'in_evaluation': False,\n",
      "            'input': 'sampler',\n",
      "            'input_compress_columns': ['obs', 'new_obs'],\n",
      "            'input_config': {},\n",
      "            'input_filesystem': None,\n",
      "            'input_filesystem_kwargs': {},\n",
      "            'input_read_batch_size': None,\n",
      "            'input_read_episodes': False,\n",
      "            'input_read_method': 'read_parquet',\n",
      "            'input_read_method_kwargs': {},\n",
      "            'input_read_sample_batches': False,\n",
      "            'input_read_schema': {},\n",
      "            'input_spaces_jsonable': True,\n",
      "            'iter_batches_kwargs': {},\n",
      "            'keep_per_episode_custom_metrics': False,\n",
      "            'kl_coeff': 0.2,\n",
      "            'kl_target': 0.01,\n",
      "            'lambda': 1.0,\n",
      "            'learner_config_dict': {},\n",
      "            'local_gpu_idx': 0,\n",
      "            'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
      "                                      'intra_op_parallelism_threads': 8},\n",
      "            'log_gradients': True,\n",
      "            'log_level': 'WARN',\n",
      "            'log_sys_usage': True,\n",
      "            'logger_config': None,\n",
      "            'logger_creator': None,\n",
      "            'lr': 5e-05,\n",
      "            'lr_schedule': None,\n",
      "            'map_batches_kwargs': {},\n",
      "            'materialize_data': False,\n",
      "            'materialize_mapped_data': True,\n",
      "            'max_num_env_runner_restarts': 1000,\n",
      "            'max_num_offline_eval_runner_restarts': 1000,\n",
      "            'max_requests_in_flight_per_aggregator_actor': 3,\n",
      "            'max_requests_in_flight_per_env_runner': 1,\n",
      "            'max_requests_in_flight_per_learner': 3,\n",
      "            'max_requests_in_flight_per_offline_eval_runner': 1,\n",
      "            'merge_env_runner_states': 'training_only',\n",
      "            'metrics_episode_collection_timeout_s': 60.0,\n",
      "            'metrics_num_episodes_for_smoothing': 100,\n",
      "            'min_sample_timesteps_per_iteration': 0,\n",
      "            'min_time_s_per_iteration': None,\n",
      "            'min_train_timesteps_per_iteration': 0,\n",
      "            'minibatch_size': 128,\n",
      "            'model': {'_disable_action_flattening': False,\n",
      "                      '_disable_preprocessor_api': False,\n",
      "                      '_time_major': False,\n",
      "                      '_use_default_native_models': -1,\n",
      "                      'always_check_shapes': False,\n",
      "                      'attention_dim': 64,\n",
      "                      'attention_head_dim': 32,\n",
      "                      'attention_init_gru_gate_bias': 2.0,\n",
      "                      'attention_memory_inference': 50,\n",
      "                      'attention_memory_training': 50,\n",
      "                      'attention_num_heads': 1,\n",
      "                      'attention_num_transformer_units': 1,\n",
      "                      'attention_position_wise_mlp_dim': 32,\n",
      "                      'attention_use_n_prev_actions': 0,\n",
      "                      'attention_use_n_prev_rewards': 0,\n",
      "                      'conv_activation': 'relu',\n",
      "                      'conv_bias_initializer': None,\n",
      "                      'conv_bias_initializer_config': None,\n",
      "                      'conv_filters': None,\n",
      "                      'conv_kernel_initializer': None,\n",
      "                      'conv_kernel_initializer_config': None,\n",
      "                      'conv_transpose_bias_initializer': None,\n",
      "                      'conv_transpose_bias_initializer_config': None,\n",
      "                      'conv_transpose_kernel_initializer': None,\n",
      "                      'conv_transpose_kernel_initializer_config': None,\n",
      "                      'custom_action_dist': None,\n",
      "                      'custom_model': None,\n",
      "                      'custom_model_config': {},\n",
      "                      'custom_preprocessor': None,\n",
      "                      'dim': 84,\n",
      "                      'encoder_latent_dim': None,\n",
      "                      'fcnet_activation': 'tanh',\n",
      "                      'fcnet_bias_initializer': None,\n",
      "                      'fcnet_bias_initializer_config': None,\n",
      "                      'fcnet_hiddens': [256, 256],\n",
      "                      'fcnet_weights_initializer': None,\n",
      "                      'fcnet_weights_initializer_config': None,\n",
      "                      'framestack': True,\n",
      "                      'free_log_std': False,\n",
      "                      'grayscale': False,\n",
      "                      'log_std_clip_param': 20.0,\n",
      "                      'lstm_bias_initializer': None,\n",
      "                      'lstm_bias_initializer_config': None,\n",
      "                      'lstm_cell_size': 256,\n",
      "                      'lstm_use_prev_action': False,\n",
      "                      'lstm_use_prev_action_reward': -1,\n",
      "                      'lstm_use_prev_reward': False,\n",
      "                      'lstm_weights_initializer': None,\n",
      "                      'lstm_weights_initializer_config': None,\n",
      "                      'max_seq_len': 20,\n",
      "                      'no_final_linear': False,\n",
      "                      'post_fcnet_activation': 'relu',\n",
      "                      'post_fcnet_bias_initializer': None,\n",
      "                      'post_fcnet_bias_initializer_config': None,\n",
      "                      'post_fcnet_hiddens': [],\n",
      "                      'post_fcnet_weights_initializer': None,\n",
      "                      'post_fcnet_weights_initializer_config': None,\n",
      "                      'use_attention': False,\n",
      "                      'use_lstm': False,\n",
      "                      'vf_share_layers': False,\n",
      "                      'zero_mean': True},\n",
      "            'normalize_actions': True,\n",
      "            'num_aggregator_actors_per_learner': 0,\n",
      "            'num_consecutive_env_runner_failures_tolerance': 100,\n",
      "            'num_cpus_for_main_process': 1,\n",
      "            'num_cpus_per_env_runner': 1,\n",
      "            'num_cpus_per_learner': 'auto',\n",
      "            'num_cpus_per_offline_eval_runner': 1,\n",
      "            'num_env_runners': 2,\n",
      "            'num_envs_per_env_runner': 1,\n",
      "            'num_epochs': 30,\n",
      "            'num_gpus': 1,\n",
      "            'num_gpus_per_env_runner': 0,\n",
      "            'num_gpus_per_learner': 0,\n",
      "            'num_gpus_per_offline_eval_runner': 0,\n",
      "            'num_learners': 0,\n",
      "            'num_offline_eval_runners': 0,\n",
      "            'observation_filter': 'NoFilter',\n",
      "            'observation_fn': None,\n",
      "            'observation_space': None,\n",
      "            'off_policy_estimation_methods': {},\n",
      "            'offline_data_class': None,\n",
      "            'offline_eval_batch_size_per_runner': 256,\n",
      "            'offline_eval_rl_module_inference_only': False,\n",
      "            'offline_eval_runner_class': None,\n",
      "            'offline_eval_runner_health_probe_timeout_s': 30.0,\n",
      "            'offline_eval_runner_restore_timeout_s': 1800.0,\n",
      "            'offline_evaluation_duration': 1,\n",
      "            'offline_evaluation_interval': None,\n",
      "            'offline_evaluation_parallel_to_training': False,\n",
      "            'offline_evaluation_timeout_s': 120.0,\n",
      "            'offline_evaluation_type': None,\n",
      "            'offline_loss_for_module_fn': None,\n",
      "            'offline_sampling': False,\n",
      "            'ope_split_batch_by_episode': True,\n",
      "            'optimizer': {},\n",
      "            'output': None,\n",
      "            'output_compress_columns': ['obs', 'new_obs'],\n",
      "            'output_config': {},\n",
      "            'output_filesystem': None,\n",
      "            'output_filesystem_kwargs': {},\n",
      "            'output_max_file_size': 67108864,\n",
      "            'output_max_rows_per_file': None,\n",
      "            'output_write_episodes': True,\n",
      "            'output_write_method': 'write_parquet',\n",
      "            'output_write_method_kwargs': {},\n",
      "            'output_write_remaining_data': False,\n",
      "            'placement_strategy': 'PACK',\n",
      "            'policies': {'default_policy': (None, None, None, None)},\n",
      "            'policies_to_train': None,\n",
      "            'policy_map_cache': -1,\n",
      "            'policy_map_capacity': 100,\n",
      "            'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x723b51995ea0>,\n",
      "            'policy_states_are_swappable': False,\n",
      "            'postprocess_inputs': False,\n",
      "            'prelearner_buffer_class': None,\n",
      "            'prelearner_buffer_kwargs': {},\n",
      "            'prelearner_class': None,\n",
      "            'prelearner_module_synch_period': 10,\n",
      "            'preprocessor_pref': 'deepmind',\n",
      "            'remote_env_batch_wait_ms': 0,\n",
      "            'remote_worker_envs': False,\n",
      "            'render_env': False,\n",
      "            'replay_sequence_length': None,\n",
      "            'restart_failed_env_runners': True,\n",
      "            'restart_failed_offline_eval_runners': True,\n",
      "            'restart_failed_sub_environments': False,\n",
      "            'rollout_fragment_length': 'auto',\n",
      "            'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
      "            'sample_timeout_s': 60.0,\n",
      "            'sampler_perf_stats_ema_coef': None,\n",
      "            'seed': None,\n",
      "            'sgd_minibatch_size': -1,\n",
      "            'shuffle_batch_per_epoch': True,\n",
      "            'shuffle_buffer_size': 0,\n",
      "            'simple_optimizer': False,\n",
      "            'sync_filters_on_rollout_workers_timeout_s': 10.0,\n",
      "            'synchronize_filters': -1,\n",
      "            'tf_session_args': {'allow_soft_placement': True,\n",
      "                                'device_count': {'CPU': 1},\n",
      "                                'gpu_options': {'allow_growth': True},\n",
      "                                'inter_op_parallelism_threads': 2,\n",
      "                                'intra_op_parallelism_threads': 2,\n",
      "                                'log_device_placement': False},\n",
      "            'torch_compile_learner': False,\n",
      "            'torch_compile_learner_dynamo_backend': 'inductor',\n",
      "            'torch_compile_learner_dynamo_mode': None,\n",
      "            'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>,\n",
      "            'torch_compile_worker': False,\n",
      "            'torch_compile_worker_dynamo_backend': 'onnxrt',\n",
      "            'torch_compile_worker_dynamo_mode': None,\n",
      "            'torch_ddp_kwargs': {},\n",
      "            'torch_skip_nan_gradients': False,\n",
      "            'train_batch_size': 4000,\n",
      "            'update_worker_filter_stats': True,\n",
      "            'use_critic': True,\n",
      "            'use_gae': True,\n",
      "            'use_kl_loss': True,\n",
      "            'use_worker_filter_stats': True,\n",
      "            'validate_env_runners_after_construction': True,\n",
      "            'validate_offline_eval_runners_after_construction': True,\n",
      "            'vf_clip_param': 10.0,\n",
      "            'vf_loss_coeff': 1.0,\n",
      "            'vf_share_layers': -1,\n",
      "            'worker_cls': -1},\n",
      " 'date': '2025-07-29_16-43-16',\n",
      " 'done': False,\n",
      " 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0},\n",
      " 'env_runners': {'agent_episode_return_mean': {'default_agent': -554.78},\n",
      "                 'env_reset_timer': np.float64(0.00033264499870711006),\n",
      "                 'env_step_timer': np.float64(7.498879828390158e-05),\n",
      "                 'env_to_module_connector': {'connector_pipeline_timer': np.float64(0.00019879955846914868),\n",
      "                                             'timers': {'connectors': {'add_observations_from_episodes_to_batch': np.float64(7.908769839506571e-06),\n",
      "                                                                       'add_states_from_episodes_to_batch': np.float64(4.77602515743815e-06),\n",
      "                                                                       'add_time_dim_to_batch_and_zero_pad': np.float64(7.569360915432413e-06),\n",
      "                                                                       'batch_individual_items': np.float64(2.0705674504979667e-05),\n",
      "                                                                       'flatten_observations': np.float64(4.5422085008598705e-05),\n",
      "                                                                       'numpy_to_tensor': np.float64(3.349576406917533e-05)}}},\n",
      "                 'env_to_module_sum_episodes_length_in': np.float64(91.12769937757962),\n",
      "                 'env_to_module_sum_episodes_length_out': np.float64(91.12769937757962),\n",
      "                 'episode_duration_sec_mean': 0.1901032950798981,\n",
      "                 'episode_len_max': 200,\n",
      "                 'episode_len_mean': 195.8,\n",
      "                 'episode_len_min': 84,\n",
      "                 'episode_return_max': -207.0,\n",
      "                 'episode_return_mean': -554.78,\n",
      "                 'episode_return_min': -704.0,\n",
      "                 'module_episode_return_mean': {'default_policy': -554.78},\n",
      "                 'module_to_env_connector': {'connector_pipeline_timer': np.float64(0.00039579020186641836),\n",
      "                                             'timers': {'connectors': {'get_actions': np.float64(0.0001698358008519742),\n",
      "                                                                       'listify_data_for_vector_env': np.float64(3.3767352803442755e-05),\n",
      "                                                                       'normalize_and_clip_actions': np.float64(2.9688264921662533e-05),\n",
      "                                                                       'remove_single_ts_time_rank_from_batch': np.float64(1.929330733387074e-06),\n",
      "                                                                       'tensor_to_numpy': np.float64(5.193025964146371e-05),\n",
      "                                                                       'un_batch_to_individual_items': np.float64(1.755689380797352e-05)}}},\n",
      "                 'num_agent_steps_sampled': {'default_agent': 4000.0},\n",
      "                 'num_agent_steps_sampled_lifetime': {'default_agent': 24000.0},\n",
      "                 'num_env_steps_sampled': 4000.0,\n",
      "                 'num_env_steps_sampled_lifetime': 24000.0,\n",
      "                 'num_env_steps_sampled_lifetime_throughput': np.float64(72.18823395665014),\n",
      "                 'num_episodes': 21.0,\n",
      "                 'num_episodes_lifetime': 121.0,\n",
      "                 'num_module_steps_sampled': {'default_policy': 4000.0},\n",
      "                 'num_module_steps_sampled_lifetime': {'default_policy': 24000.0},\n",
      "                 'rlmodule_inference_timer': np.float64(0.00012344230644492141),\n",
      "                 'sample': np.float64(2.051221846475511),\n",
      "                 'time_between_sampling': np.float64(17.402905822985637),\n",
      "                 'weights_seq_no': 5.0},\n",
      " 'fault_tolerance': {'num_healthy_workers': 2, 'num_remote_worker_restarts': 0},\n",
      " 'hostname': 'lukelo-Blade-15-Advanced-Model-Early-2020-RZ09-033',\n",
      " 'iterations_since_restore': 6,\n",
      " 'learners': {'__all_modules__': {'learner_connector': {'connector_pipeline_timer': 0.13129278027365776,\n",
      "                                                        'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.061178590750548066,\n",
      "                                                                                  'add_observations_from_episodes_to_batch': 0.0002165180500214636,\n",
      "                                                                                  'add_one_ts_to_episodes_and_truncate': 0.006164245853421701,\n",
      "                                                                                  'add_states_from_episodes_to_batch': 8.296384009403867e-06,\n",
      "                                                                                  'add_time_dim_to_batch_and_zero_pad': 2.2818187018372564e-05,\n",
      "                                                                                  'batch_individual_items': 0.04057391136485817,\n",
      "                                                                                  'general_advantage_estimation': 0.022607290734058205,\n",
      "                                                                                  'numpy_to_tensor': 0.0001541828878075002}}},\n",
      "                                  'learner_connector_sum_episodes_length_in': 4000.0,\n",
      "                                  'learner_connector_sum_episodes_length_out': 4021.0298999999995,\n",
      "                                  'num_env_steps_trained': 3793689,\n",
      "                                  'num_env_steps_trained_lifetime': 22753647,\n",
      "                                  'num_env_steps_trained_lifetime_throughput': 569023.6539185536,\n",
      "                                  'num_module_steps_trained': 120704,\n",
      "                                  'num_module_steps_trained_lifetime': 724224,\n",
      "                                  'num_module_steps_trained_lifetime_throughput': 18114.36580073509,\n",
      "                                  'num_module_steps_trained_throughput': 18113.542407316385,\n",
      "                                  'num_non_trainable_parameters': 0,\n",
      "                                  'num_trainable_parameters': 389895},\n",
      "              'default_policy': {'curr_entropy_coeff': 0.0,\n",
      "                                 'curr_kl_coeff': 0.675000011920929,\n",
      "                                 'default_optimizer_learning_rate': 5e-05,\n",
      "                                 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0),\n",
      "                                 'entropy': np.float32(1.6082717),\n",
      "                                 'gradients_default_optimizer_global_norm': np.float32(0.70713204),\n",
      "                                 'mean_kl_loss': np.float32(0.019891564),\n",
      "                                 'module_train_batch_size_mean': 128.0,\n",
      "                                 'num_module_steps_trained': 120704,\n",
      "                                 'num_module_steps_trained_lifetime': 724224,\n",
      "                                 'num_module_steps_trained_lifetime_throughput': 18112.72608047812,\n",
      "                                 'num_trainable_parameters': 389895,\n",
      "                                 'policy_loss': np.float32(0.048561275),\n",
      "                                 'total_loss': np.float32(9.929624),\n",
      "                                 'vf_explained_var': np.float32(0.0014907122),\n",
      "                                 'vf_loss': np.float32(9.867636),\n",
      "                                 'vf_loss_unclipped': np.float32(28831.219),\n",
      "                                 'weights_seq_no': 6.0}},\n",
      " 'node_ip': '10.9.22.224',\n",
      " 'num_env_steps_sampled_lifetime': 24000.0,\n",
      " 'num_training_step_calls_per_iteration': 1,\n",
      " 'perf': {'cpu_util_percent': np.float64(43.45333333333333),\n",
      "          'ram_util_percent': np.float64(51.58666666666668)},\n",
      " 'pid': 125052,\n",
      " 'time_since_restore': 57.7028534412384,\n",
      " 'time_this_iter_s': 10.020583391189575,\n",
      " 'time_total_s': 57.7028534412384,\n",
      " 'timers': {'env_runner_sampling_timer': 2.1168335703303582,\n",
      "            'learner_update_timer': 7.3184881750720105,\n",
      "            'restore_env_runners': 1.3415944864070309e-05,\n",
      "            'synch_env_connectors': 0.0019244518253127012,\n",
      "            'synch_weights': 0.0019220209586444722,\n",
      "            'training_iteration': 9.439851054261865,\n",
      "            'training_step': 9.439601269303536},\n",
      " 'timestamp': 1753800196,\n",
      " 'training_iteration': 6,\n",
      " 'trial_id': 'default'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2 \n",
      "{'config': {'_disable_action_flattening': False,\n",
      "            '_disable_execution_plan_api': -1,\n",
      "            '_disable_initialize_loss_from_dummy_batch': False,\n",
      "            '_disable_preprocessor_api': False,\n",
      "            '_dont_auto_sync_env_runner_states': False,\n",
      "            '_enable_rl_module_api': -1,\n",
      "            '_env_to_module_connector': <function <lambda> at 0x723958b9c3a0>,\n",
      "            '_fake_gpus': False,\n",
      "            '_is_atari': None,\n",
      "            '_is_online': True,\n",
      "            '_learner_class': None,\n",
      "            '_learner_connector': None,\n",
      "            '_model_config': {},\n",
      "            '_module_to_env_connector': None,\n",
      "            '_per_module_overrides': {},\n",
      "            '_prior_exploration_config': {'type': 'StochasticSampling'},\n",
      "            '_rl_module_spec': None,\n",
      "            '_tf_policy_handles_more_than_one_loss': False,\n",
      "            '_torch_grad_scaler_class': None,\n",
      "            '_torch_lr_scheduler_classes': None,\n",
      "            '_train_batch_size_per_learner': None,\n",
      "            '_use_msgpack_checkpoints': False,\n",
      "            '_validate_config': True,\n",
      "            'action_mask_key': 'action_mask',\n",
      "            'action_space': None,\n",
      "            'actions_in_input_normalized': False,\n",
      "            'add_default_connectors_to_env_to_module_pipeline': True,\n",
      "            'add_default_connectors_to_learner_pipeline': True,\n",
      "            'add_default_connectors_to_module_to_env_pipeline': True,\n",
      "            'algorithm_config_overrides_per_module': {},\n",
      "            'always_attach_evaluation_results': -1,\n",
      "            'auto_wrap_old_gym_envs': -1,\n",
      "            'batch_mode': 'truncate_episodes',\n",
      "            'broadcast_env_runner_states': True,\n",
      "            'broadcast_offline_eval_runner_states': False,\n",
      "            'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>,\n",
      "            'callbacks_on_algorithm_init': None,\n",
      "            'callbacks_on_checkpoint_loaded': None,\n",
      "            'callbacks_on_env_runners_recreated': None,\n",
      "            'callbacks_on_environment_created': None,\n",
      "            'callbacks_on_episode_created': None,\n",
      "            'callbacks_on_episode_end': None,\n",
      "            'callbacks_on_episode_start': None,\n",
      "            'callbacks_on_episode_step': None,\n",
      "            'callbacks_on_evaluate_end': None,\n",
      "            'callbacks_on_evaluate_offline_end': None,\n",
      "            'callbacks_on_evaluate_offline_start': None,\n",
      "            'callbacks_on_evaluate_start': None,\n",
      "            'callbacks_on_offline_eval_runners_recreated': None,\n",
      "            'callbacks_on_sample_end': None,\n",
      "            'callbacks_on_train_result': None,\n",
      "            'checkpoint_trainable_policies_only': False,\n",
      "            'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>,\n",
      "            'clip_actions': False,\n",
      "            'clip_param': 0.3,\n",
      "            'clip_rewards': None,\n",
      "            'compress_observations': False,\n",
      "            'count_steps_by': 'env_steps',\n",
      "            'create_env_on_driver': False,\n",
      "            'create_local_env_runner': True,\n",
      "            'custom_async_evaluation_function': -1,\n",
      "            'custom_eval_function': None,\n",
      "            'custom_resources_per_env_runner': {},\n",
      "            'custom_resources_per_offline_eval_runner': {},\n",
      "            'dataset_num_iters_per_eval_runner': 1,\n",
      "            'dataset_num_iters_per_learner': None,\n",
      "            'delay_between_env_runner_restarts_s': 60.0,\n",
      "            'disable_env_checking': False,\n",
      "            'eager_max_retraces': 20,\n",
      "            'eager_tracing': True,\n",
      "            'enable_async_evaluation': -1,\n",
      "            'enable_connectors': -1,\n",
      "            'enable_env_runner_and_connector_v2': True,\n",
      "            'enable_rl_module_and_learner': True,\n",
      "            'enable_tf1_exec_eagerly': False,\n",
      "            'entropy_coeff': 0.0,\n",
      "            'entropy_coeff_schedule': None,\n",
      "            'env': 'Taxi-v3',\n",
      "            'env_config': {},\n",
      "            'env_runner_cls': None,\n",
      "            'env_runner_health_probe_timeout_s': 30.0,\n",
      "            'env_runner_restore_timeout_s': 1800.0,\n",
      "            'env_task_fn': -1,\n",
      "            'episode_lookback_horizon': 1,\n",
      "            'episodes_to_numpy': True,\n",
      "            'evaluation_auto_duration_max_env_steps_per_sample': 2000,\n",
      "            'evaluation_auto_duration_min_env_steps_per_sample': 100,\n",
      "            'evaluation_config': None,\n",
      "            'evaluation_duration': 10,\n",
      "            'evaluation_duration_unit': 'episodes',\n",
      "            'evaluation_force_reset_envs_before_iteration': True,\n",
      "            'evaluation_interval': None,\n",
      "            'evaluation_num_env_runners': 1,\n",
      "            'evaluation_parallel_to_training': False,\n",
      "            'evaluation_sample_timeout_s': 120.0,\n",
      "            'exploration_config': {},\n",
      "            'explore': True,\n",
      "            'export_native_model_files': False,\n",
      "            'extra_python_environs_for_driver': {},\n",
      "            'extra_python_environs_for_worker': {},\n",
      "            'fake_sampler': False,\n",
      "            'framework': 'torch',\n",
      "            'gamma': 0.99,\n",
      "            'grad_clip': None,\n",
      "            'grad_clip_by': 'global_norm',\n",
      "            'gym_env_vectorize_mode': 'SYNC',\n",
      "            'ignore_env_runner_failures': False,\n",
      "            'ignore_final_observation': False,\n",
      "            'ignore_offline_eval_runner_failures': False,\n",
      "            'in_evaluation': False,\n",
      "            'input': 'sampler',\n",
      "            'input_compress_columns': ['obs', 'new_obs'],\n",
      "            'input_config': {},\n",
      "            'input_filesystem': None,\n",
      "            'input_filesystem_kwargs': {},\n",
      "            'input_read_batch_size': None,\n",
      "            'input_read_episodes': False,\n",
      "            'input_read_method': 'read_parquet',\n",
      "            'input_read_method_kwargs': {},\n",
      "            'input_read_sample_batches': False,\n",
      "            'input_read_schema': {},\n",
      "            'input_spaces_jsonable': True,\n",
      "            'iter_batches_kwargs': {},\n",
      "            'keep_per_episode_custom_metrics': False,\n",
      "            'kl_coeff': 0.2,\n",
      "            'kl_target': 0.01,\n",
      "            'lambda': 1.0,\n",
      "            'learner_config_dict': {},\n",
      "            'local_gpu_idx': 0,\n",
      "            'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
      "                                      'intra_op_parallelism_threads': 8},\n",
      "            'log_gradients': True,\n",
      "            'log_level': 'WARN',\n",
      "            'log_sys_usage': True,\n",
      "            'logger_config': None,\n",
      "            'logger_creator': None,\n",
      "            'lr': 5e-05,\n",
      "            'lr_schedule': None,\n",
      "            'map_batches_kwargs': {},\n",
      "            'materialize_data': False,\n",
      "            'materialize_mapped_data': True,\n",
      "            'max_num_env_runner_restarts': 1000,\n",
      "            'max_num_offline_eval_runner_restarts': 1000,\n",
      "            'max_requests_in_flight_per_aggregator_actor': 3,\n",
      "            'max_requests_in_flight_per_env_runner': 1,\n",
      "            'max_requests_in_flight_per_learner': 3,\n",
      "            'max_requests_in_flight_per_offline_eval_runner': 1,\n",
      "            'merge_env_runner_states': 'training_only',\n",
      "            'metrics_episode_collection_timeout_s': 60.0,\n",
      "            'metrics_num_episodes_for_smoothing': 100,\n",
      "            'min_sample_timesteps_per_iteration': 0,\n",
      "            'min_time_s_per_iteration': None,\n",
      "            'min_train_timesteps_per_iteration': 0,\n",
      "            'minibatch_size': 128,\n",
      "            'model': {'_disable_action_flattening': False,\n",
      "                      '_disable_preprocessor_api': False,\n",
      "                      '_time_major': False,\n",
      "                      '_use_default_native_models': -1,\n",
      "                      'always_check_shapes': False,\n",
      "                      'attention_dim': 64,\n",
      "                      'attention_head_dim': 32,\n",
      "                      'attention_init_gru_gate_bias': 2.0,\n",
      "                      'attention_memory_inference': 50,\n",
      "                      'attention_memory_training': 50,\n",
      "                      'attention_num_heads': 1,\n",
      "                      'attention_num_transformer_units': 1,\n",
      "                      'attention_position_wise_mlp_dim': 32,\n",
      "                      'attention_use_n_prev_actions': 0,\n",
      "                      'attention_use_n_prev_rewards': 0,\n",
      "                      'conv_activation': 'relu',\n",
      "                      'conv_bias_initializer': None,\n",
      "                      'conv_bias_initializer_config': None,\n",
      "                      'conv_filters': None,\n",
      "                      'conv_kernel_initializer': None,\n",
      "                      'conv_kernel_initializer_config': None,\n",
      "                      'conv_transpose_bias_initializer': None,\n",
      "                      'conv_transpose_bias_initializer_config': None,\n",
      "                      'conv_transpose_kernel_initializer': None,\n",
      "                      'conv_transpose_kernel_initializer_config': None,\n",
      "                      'custom_action_dist': None,\n",
      "                      'custom_model': None,\n",
      "                      'custom_model_config': {},\n",
      "                      'custom_preprocessor': None,\n",
      "                      'dim': 84,\n",
      "                      'encoder_latent_dim': None,\n",
      "                      'fcnet_activation': 'tanh',\n",
      "                      'fcnet_bias_initializer': None,\n",
      "                      'fcnet_bias_initializer_config': None,\n",
      "                      'fcnet_hiddens': [256, 256],\n",
      "                      'fcnet_weights_initializer': None,\n",
      "                      'fcnet_weights_initializer_config': None,\n",
      "                      'framestack': True,\n",
      "                      'free_log_std': False,\n",
      "                      'grayscale': False,\n",
      "                      'log_std_clip_param': 20.0,\n",
      "                      'lstm_bias_initializer': None,\n",
      "                      'lstm_bias_initializer_config': None,\n",
      "                      'lstm_cell_size': 256,\n",
      "                      'lstm_use_prev_action': False,\n",
      "                      'lstm_use_prev_action_reward': -1,\n",
      "                      'lstm_use_prev_reward': False,\n",
      "                      'lstm_weights_initializer': None,\n",
      "                      'lstm_weights_initializer_config': None,\n",
      "                      'max_seq_len': 20,\n",
      "                      'no_final_linear': False,\n",
      "                      'post_fcnet_activation': 'relu',\n",
      "                      'post_fcnet_bias_initializer': None,\n",
      "                      'post_fcnet_bias_initializer_config': None,\n",
      "                      'post_fcnet_hiddens': [],\n",
      "                      'post_fcnet_weights_initializer': None,\n",
      "                      'post_fcnet_weights_initializer_config': None,\n",
      "                      'use_attention': False,\n",
      "                      'use_lstm': False,\n",
      "                      'vf_share_layers': False,\n",
      "                      'zero_mean': True},\n",
      "            'normalize_actions': True,\n",
      "            'num_aggregator_actors_per_learner': 0,\n",
      "            'num_consecutive_env_runner_failures_tolerance': 100,\n",
      "            'num_cpus_for_main_process': 1,\n",
      "            'num_cpus_per_env_runner': 1,\n",
      "            'num_cpus_per_learner': 'auto',\n",
      "            'num_cpus_per_offline_eval_runner': 1,\n",
      "            'num_env_runners': 2,\n",
      "            'num_envs_per_env_runner': 1,\n",
      "            'num_epochs': 30,\n",
      "            'num_gpus': 1,\n",
      "            'num_gpus_per_env_runner': 0,\n",
      "            'num_gpus_per_learner': 0,\n",
      "            'num_gpus_per_offline_eval_runner': 0,\n",
      "            'num_learners': 0,\n",
      "            'num_offline_eval_runners': 0,\n",
      "            'observation_filter': 'NoFilter',\n",
      "            'observation_fn': None,\n",
      "            'observation_space': None,\n",
      "            'off_policy_estimation_methods': {},\n",
      "            'offline_data_class': None,\n",
      "            'offline_eval_batch_size_per_runner': 256,\n",
      "            'offline_eval_rl_module_inference_only': False,\n",
      "            'offline_eval_runner_class': None,\n",
      "            'offline_eval_runner_health_probe_timeout_s': 30.0,\n",
      "            'offline_eval_runner_restore_timeout_s': 1800.0,\n",
      "            'offline_evaluation_duration': 1,\n",
      "            'offline_evaluation_interval': None,\n",
      "            'offline_evaluation_parallel_to_training': False,\n",
      "            'offline_evaluation_timeout_s': 120.0,\n",
      "            'offline_evaluation_type': None,\n",
      "            'offline_loss_for_module_fn': None,\n",
      "            'offline_sampling': False,\n",
      "            'ope_split_batch_by_episode': True,\n",
      "            'optimizer': {},\n",
      "            'output': None,\n",
      "            'output_compress_columns': ['obs', 'new_obs'],\n",
      "            'output_config': {},\n",
      "            'output_filesystem': None,\n",
      "            'output_filesystem_kwargs': {},\n",
      "            'output_max_file_size': 67108864,\n",
      "            'output_max_rows_per_file': None,\n",
      "            'output_write_episodes': True,\n",
      "            'output_write_method': 'write_parquet',\n",
      "            'output_write_method_kwargs': {},\n",
      "            'output_write_remaining_data': False,\n",
      "            'placement_strategy': 'PACK',\n",
      "            'policies': {'default_policy': (None, None, None, None)},\n",
      "            'policies_to_train': None,\n",
      "            'policy_map_cache': -1,\n",
      "            'policy_map_capacity': 100,\n",
      "            'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x723b51995ea0>,\n",
      "            'policy_states_are_swappable': False,\n",
      "            'postprocess_inputs': False,\n",
      "            'prelearner_buffer_class': None,\n",
      "            'prelearner_buffer_kwargs': {},\n",
      "            'prelearner_class': None,\n",
      "            'prelearner_module_synch_period': 10,\n",
      "            'preprocessor_pref': 'deepmind',\n",
      "            'remote_env_batch_wait_ms': 0,\n",
      "            'remote_worker_envs': False,\n",
      "            'render_env': False,\n",
      "            'replay_sequence_length': None,\n",
      "            'restart_failed_env_runners': True,\n",
      "            'restart_failed_offline_eval_runners': True,\n",
      "            'restart_failed_sub_environments': False,\n",
      "            'rollout_fragment_length': 'auto',\n",
      "            'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
      "            'sample_timeout_s': 60.0,\n",
      "            'sampler_perf_stats_ema_coef': None,\n",
      "            'seed': None,\n",
      "            'sgd_minibatch_size': -1,\n",
      "            'shuffle_batch_per_epoch': True,\n",
      "            'shuffle_buffer_size': 0,\n",
      "            'simple_optimizer': False,\n",
      "            'sync_filters_on_rollout_workers_timeout_s': 10.0,\n",
      "            'synchronize_filters': -1,\n",
      "            'tf_session_args': {'allow_soft_placement': True,\n",
      "                                'device_count': {'CPU': 1},\n",
      "                                'gpu_options': {'allow_growth': True},\n",
      "                                'inter_op_parallelism_threads': 2,\n",
      "                                'intra_op_parallelism_threads': 2,\n",
      "                                'log_device_placement': False},\n",
      "            'torch_compile_learner': False,\n",
      "            'torch_compile_learner_dynamo_backend': 'inductor',\n",
      "            'torch_compile_learner_dynamo_mode': None,\n",
      "            'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>,\n",
      "            'torch_compile_worker': False,\n",
      "            'torch_compile_worker_dynamo_backend': 'onnxrt',\n",
      "            'torch_compile_worker_dynamo_mode': None,\n",
      "            'torch_ddp_kwargs': {},\n",
      "            'torch_skip_nan_gradients': False,\n",
      "            'train_batch_size': 4000,\n",
      "            'update_worker_filter_stats': True,\n",
      "            'use_critic': True,\n",
      "            'use_gae': True,\n",
      "            'use_kl_loss': True,\n",
      "            'use_worker_filter_stats': True,\n",
      "            'validate_env_runners_after_construction': True,\n",
      "            'validate_offline_eval_runners_after_construction': True,\n",
      "            'vf_clip_param': 10.0,\n",
      "            'vf_loss_coeff': 1.0,\n",
      "            'vf_share_layers': -1,\n",
      "            'worker_cls': -1},\n",
      " 'date': '2025-07-29_16-43-26',\n",
      " 'done': False,\n",
      " 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0},\n",
      " 'env_runners': {'agent_episode_return_mean': {'default_agent': -521.24},\n",
      "                 'env_reset_timer': np.float64(0.00033264499870711006),\n",
      "                 'env_step_timer': np.float64(7.685979927420634e-05),\n",
      "                 'env_to_module_connector': {'connector_pipeline_timer': np.float64(0.00020596058673516196),\n",
      "                                             'timers': {'connectors': {'add_observations_from_episodes_to_batch': np.float64(8.235368556651362e-06),\n",
      "                                                                       'add_states_from_episodes_to_batch': np.float64(5.048163200638086e-06),\n",
      "                                                                       'add_time_dim_to_batch_and_zero_pad': np.float64(7.904585668435953e-06),\n",
      "                                                                       'batch_individual_items': np.float64(2.1470632877431325e-05),\n",
      "                                                                       'flatten_observations': np.float64(4.6749176392370703e-05),\n",
      "                                                                       'numpy_to_tensor': np.float64(3.477527771579217e-05)}}},\n",
      "                 'env_to_module_sum_episodes_length_in': np.float64(93.16721827395531),\n",
      "                 'env_to_module_sum_episodes_length_out': np.float64(93.16721827395531),\n",
      "                 'episode_duration_sec_mean': 0.1870626823999919,\n",
      "                 'episode_len_max': 200,\n",
      "                 'episode_len_mean': 191.9,\n",
      "                 'episode_len_min': 69,\n",
      "                 'episode_return_max': -207.0,\n",
      "                 'episode_return_mean': -521.24,\n",
      "                 'episode_return_min': -650.0,\n",
      "                 'module_episode_return_mean': {'default_policy': -521.24},\n",
      "                 'module_to_env_connector': {'connector_pipeline_timer': np.float64(0.0004007473256965593),\n",
      "                                             'timers': {'connectors': {'get_actions': np.float64(0.00017122359771750534),\n",
      "                                                                       'listify_data_for_vector_env': np.float64(3.488699485067651e-05),\n",
      "                                                                       'normalize_and_clip_actions': np.float64(3.0246856238234972e-05),\n",
      "                                                                       'remove_single_ts_time_rank_from_batch': np.float64(1.9412938745087305e-06),\n",
      "                                                                       'tensor_to_numpy': np.float64(5.2566113937409445e-05),\n",
      "                                                                       'un_batch_to_individual_items': np.float64(1.8050931648722245e-05)}}},\n",
      "                 'num_agent_steps_sampled': {'default_agent': 4000.0},\n",
      "                 'num_agent_steps_sampled_lifetime': {'default_agent': 28000.0},\n",
      "                 'num_env_steps_sampled': 4000.0,\n",
      "                 'num_env_steps_sampled_lifetime': 28000.0,\n",
      "                 'num_env_steps_sampled_lifetime_throughput': np.float64(74.28064409650216),\n",
      "                 'num_episodes': 21.0,\n",
      "                 'num_episodes_lifetime': 142.0,\n",
      "                 'num_module_steps_sampled': {'default_policy': 4000.0},\n",
      "                 'num_module_steps_sampled_lifetime': {'default_policy': 28000.0},\n",
      "                 'rlmodule_inference_timer': np.float64(0.00012761995566693034),\n",
      "                 'sample': np.float64(2.050467843975804),\n",
      "                 'time_between_sampling': np.float64(17.309432000110803),\n",
      "                 'weights_seq_no': 6.0},\n",
      " 'fault_tolerance': {'num_healthy_workers': 2, 'num_remote_worker_restarts': 0},\n",
      " 'hostname': 'lukelo-Blade-15-Advanced-Model-Early-2020-RZ09-033',\n",
      " 'iterations_since_restore': 7,\n",
      " 'learners': {'__all_modules__': {'learner_connector': {'connector_pipeline_timer': 0.1311675011509095,\n",
      "                                                        'timers': {'connectors': {'add_columns_from_episodes_to_train_batch': 0.061175910843016996,\n",
      "                                                                                  'add_observations_from_episodes_to_batch': 0.00021670831957250355,\n",
      "                                                                                  'add_one_ts_to_episodes_and_truncate': 0.0061480268648884525,\n",
      "                                                                                  'add_states_from_episodes_to_batch': 8.284940140552933e-06,\n",
      "                                                                                  'add_time_dim_to_batch_and_zero_pad': 2.2820285132141478e-05,\n",
      "                                                                                  'batch_individual_items': 0.040582673101229566,\n",
      "                                                                                  'general_advantage_estimation': 0.02249339515672866,\n",
      "                                                                                  'numpy_to_tensor': 0.00015398111897315595}}},\n",
      "                                  'learner_connector_sum_episodes_length_in': 4000.0,\n",
      "                                  'learner_connector_sum_episodes_length_out': 4021.0496009999997,\n",
      "                                  'num_env_steps_trained': 3793689,\n",
      "                                  'num_env_steps_trained_lifetime': 26547336,\n",
      "                                  'num_env_steps_trained_lifetime_throughput': 566873.794710996,\n",
      "                                  'num_module_steps_trained': 120704,\n",
      "                                  'num_module_steps_trained_lifetime': 844928,\n",
      "                                  'num_module_steps_trained_lifetime_throughput': 18045.63831788208,\n",
      "                                  'num_module_steps_trained_throughput': 18044.94445802344,\n",
      "                                  'num_non_trainable_parameters': 0,\n",
      "                                  'num_trainable_parameters': 389895},\n",
      "              'default_policy': {'curr_entropy_coeff': 0.0,\n",
      "                                 'curr_kl_coeff': 1.0125000476837158,\n",
      "                                 'default_optimizer_learning_rate': 5e-05,\n",
      "                                 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0),\n",
      "                                 'entropy': np.float32(1.5785377),\n",
      "                                 'gradients_default_optimizer_global_norm': np.float32(0.7169959),\n",
      "                                 'mean_kl_loss': np.float32(0.023492992),\n",
      "                                 'module_train_batch_size_mean': 128.0,\n",
      "                                 'num_module_steps_trained': 120704,\n",
      "                                 'num_module_steps_trained_lifetime': 844928,\n",
      "                                 'num_module_steps_trained_lifetime_throughput': 18044.2578924121,\n",
      "                                 'num_trainable_parameters': 389895,\n",
      "                                 'policy_loss': np.float32(-0.053923663),\n",
      "                                 'total_loss': np.float32(9.752652),\n",
      "                                 'vf_explained_var': np.float32(-0.0036782026),\n",
      "                                 'vf_loss': np.float32(9.790719),\n",
      "                                 'vf_loss_unclipped': np.float32(24936.467),\n",
      "                                 'weights_seq_no': 7.0}},\n",
      " 'node_ip': '10.9.22.224',\n",
      " 'num_env_steps_sampled_lifetime': 28000.0,\n",
      " 'num_training_step_calls_per_iteration': 1,\n",
      " 'perf': {'cpu_util_percent': np.float64(43.607142857142854),\n",
      "          'ram_util_percent': np.float64(51.52142857142858)},\n",
      " 'pid': 125052,\n",
      " 'time_since_restore': 67.47782063484192,\n",
      " 'time_this_iter_s': 9.774967193603516,\n",
      " 'time_total_s': 67.47782063484192,\n",
      " 'timers': {'env_runner_sampling_timer': 2.1159625052470488,\n",
      "            'learner_update_timer': 7.322646999721279,\n",
      "            'restore_env_runners': 1.3391125450553357e-05,\n",
      "            'synch_env_connectors': 0.001930749757080595,\n",
      "            'synch_weights': 0.0019222500990601328,\n",
      "            'training_iteration': 9.443145545749239,\n",
      "            'training_step': 9.442894932250494},\n",
      " 'timestamp': 1753800206,\n",
      " 'training_iteration': 7,\n",
      " 'trial_id': 'default'}\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "for i in range(3):\n",
    "    result = algo.train()\n",
    "    print(f\"Iteration {i} \")\n",
    "    pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9937f4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'env_runners': {'agent_episode_return_mean': {'default_agent': -515.0},\n",
      "                 'env_reset_timer': 0.000413251000281889,\n",
      "                 'env_step_timer': 6.971735531206349e-05,\n",
      "                 'env_to_module_connector': {'connector_pipeline_timer': 0.0001866496132408603,\n",
      "                                             'timers': {'connectors': {'add_observations_from_episodes_to_batch': 7.363182864581167e-06,\n",
      "                                                                       'add_states_from_episodes_to_batch': 4.529063367132337e-06,\n",
      "                                                                       'add_time_dim_to_batch_and_zero_pad': 6.775441536417815e-06,\n",
      "                                                                       'batch_individual_items': 1.920679267953981e-05,\n",
      "                                                                       'flatten_observations': 4.268484275914268e-05,\n",
      "                                                                       'numpy_to_tensor': 3.133181523163244e-05}}},\n",
      "                 'env_to_module_sum_episodes_length_in': 131.73765398537716,\n",
      "                 'env_to_module_sum_episodes_length_out': 131.73765398537716,\n",
      "                 'episode_duration_sec_mean': 0.1862953723000828,\n",
      "                 'episode_len_max': 200,\n",
      "                 'episode_len_mean': 200.0,\n",
      "                 'episode_len_min': 200,\n",
      "                 'episode_return_max': -344.0,\n",
      "                 'episode_return_mean': -515.0,\n",
      "                 'episode_return_min': -668.0,\n",
      "                 'module_episode_return_mean': {'default_policy': -515.0},\n",
      "                 'module_to_env_connector': {'connector_pipeline_timer': 0.0003682193008121564,\n",
      "                                             'timers': {'connectors': {'get_actions': 0.0001570110768372428,\n",
      "                                                                       'listify_data_for_vector_env': 3.1948723307947065e-05,\n",
      "                                                                       'normalize_and_clip_actions': 2.750939687453452e-05,\n",
      "                                                                       'remove_single_ts_time_rank_from_batch': 1.7406696621943201e-06,\n",
      "                                                                       'tensor_to_numpy': 5.010127228646035e-05,\n",
      "                                                                       'un_batch_to_individual_items': 1.6585175952556864e-05}}},\n",
      "                 'num_agent_steps_sampled': {'default_agent': 2000},\n",
      "                 'num_agent_steps_sampled_lifetime': {'default_agent': 2000},\n",
      "                 'num_env_steps_sampled': 2000,\n",
      "                 'num_env_steps_sampled_lifetime': 2000,\n",
      "                 'num_episodes': 10,\n",
      "                 'num_episodes_lifetime': 10,\n",
      "                 'num_module_steps_sampled': {'default_policy': 2000},\n",
      "                 'num_module_steps_sampled_lifetime': {'default_policy': 2000},\n",
      "                 'rlmodule_inference_timer': 0.00011308641632939379,\n",
      "                 'sample': 1.8956446329975734,\n",
      "                 'weights_seq_no': 7.0}}\n"
     ]
    }
   ],
   "source": [
    "# ... and evaluate it.\n",
    "pprint(algo.evaluate())\n",
    "\n",
    "# Release the algo's resources (remote actors, like EnvRunners and Learners).\n",
    "algo.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33c5a284",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83a06bb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'local_worker'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m total_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Zugriff auf Policy über den Worker\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m policy \u001b[38;5;241m=\u001b[39m \u001b[43malgo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocal_worker\u001b[49m()\u001b[38;5;241m.\u001b[39mpolicy_map[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault_policy\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[1;32m     13\u001b[0m     action \u001b[38;5;241m=\u001b[39m policy\u001b[38;5;241m.\u001b[39mcompute_single_action(obs)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'local_worker'"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "# Test-Environment vorbereiten\n",
    "env = gym.make(\"Taxi-v3\")\n",
    "obs, _ = env.reset()\n",
    "done = False\n",
    "total_reward = 0\n",
    "\n",
    "# Zugriff auf Policy über den Worker\n",
    "policy = algo.workers.local_worker().policy_map[\"default_policy\"]\n",
    "\n",
    "while not done:\n",
    "    action = policy.compute_single_action(obs)\n",
    "    obs, reward, terminated, truncated, _ = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    total_reward += reward\n",
    "    env.render()\n",
    "\n",
    "print(f\"Total reward in test episode: {total_reward}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc05cf90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b8897d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 16:38:43,568\tINFO worker.py:1765 -- Calling ray.init() again after it has already been called.\n",
      "[2025-07-29 16:38:43,615 E 125052 125052] core_worker.cc:2740: Actor with class name: 'RolloutWorker' and ID: '32066a3ea73cbb53063d25f201000000' has constructor arguments in the object store and max_restarts > 0. If the arguments in the object store go out of scope or are lost, the actor restart will fail. See https://github.com/ray-project/ray/issues/53727 for more details.\n",
      "[2025-07-29 16:38:43,664 E 125052 125052] core_worker.cc:2740: Actor with class name: 'RolloutWorker' and ID: 'd21aa701d5948e7b34406da701000000' has constructor arguments in the object store and max_restarts > 0. If the arguments in the object store go out of scope or are lost, the actor restart will fail. See https://github.com/ray-project/ray/issues/53727 for more details.\n",
      "2025-07-29 16:38:46,771\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Iteration 1\n",
      "Iteration 2\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 43\u001b[0m\n\u001b[1;32m     41\u001b[0m obs_vector \u001b[38;5;241m=\u001b[39m one_hot(obs, obs_space_size)  \u001b[38;5;66;03m# ← One-Hot\u001b[39;00m\n\u001b[1;32m     42\u001b[0m action \u001b[38;5;241m=\u001b[39m policy\u001b[38;5;241m.\u001b[39mcompute_single_action(obs_vector)\n\u001b[0;32m---> 43\u001b[0m obs, reward, terminated, truncated, _ \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m done \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n\u001b[1;32m     45\u001b[0m total_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n",
      "File \u001b[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/gymnasium/wrappers/common.py:125\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28mself\u001b[39m, action: ActType\n\u001b[1;32m    114\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[ObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m    115\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m \n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m     observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/gymnasium/wrappers/common.py:393\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/gymnasium/core.py:322\u001b[0m, in \u001b[0;36mWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28mself\u001b[39m, action: WrapperActType\n\u001b[1;32m    320\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m    321\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Uses the :meth:`step` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/gymnasium/wrappers/common.py:283\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchecked_step \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchecked_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43menv_step_passive_checker\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(action)\n",
      "File \u001b[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:207\u001b[0m, in \u001b[0;36menv_step_passive_checker\u001b[0;34m(env, action)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"A passive check for the environment step, investigating the returning data then returning the data unchanged.\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;66;03m# We don't check the action as for some environments then out-of-bounds values can be given\u001b[39;00m\n\u001b[0;32m--> 207\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    209\u001b[0m     result, \u001b[38;5;28mtuple\u001b[39m\n\u001b[1;32m    210\u001b[0m ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpects step result to be a tuple, actual type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(result)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/gymnasium/envs/toy_text/taxi.py:289\u001b[0m, in \u001b[0;36mTaxiEnv.step\u001b[0;34m(self, a)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, a):\n\u001b[0;32m--> 289\u001b[0m     transitions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mP\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43ma\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    290\u001b[0m     i \u001b[38;5;241m=\u001b[39m categorical_sample([t[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m transitions], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnp_random)\n\u001b[1;32m    291\u001b[0m     p, s, r, t \u001b[38;5;241m=\u001b[39m transitions[i]\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b6bf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "git config --global user.email \"nerdvsn@gmail.com\"\n",
    "ssh-keygen -t ed25519 -C \"nerdvsn@gmail.com\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2255eaf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
